{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f78015a3",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# LangExtract OpenAI Plugin Examples\n",
    "\n",
    "This notebook demonstrates how to use the OpenAI and Azure OpenAI providers with LangExtract for structured data extraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "47fb0d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import langextract as lx\n",
    "from langextract_openai import OpenAILanguageModel, AzureOpenAILanguageModel\n",
    "import textwrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4279c82e",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = textwrap.dedent(\"\"\"\\\n",
    "    Extract characters, emotions, and relationships in order of appearance.\n",
    "    Use exact text for extractions. Do not paraphrase or overlap entities.\n",
    "    Provide meaningful attributes for each entity to add context.\"\"\")\n",
    "\n",
    "# 2. Provide a high-quality example to guide the model\n",
    "examples = [\n",
    "    lx.data.ExampleData(\n",
    "        text=\"ROMEO. But soft! What light through yonder window breaks? It is the east, and Juliet is the sun.\",\n",
    "        extractions=[\n",
    "            lx.data.Extraction(\n",
    "                extraction_class=\"character\",\n",
    "                extraction_text=\"ROMEO\",\n",
    "                attributes={\"emotional_state\": \"wonder\"}\n",
    "            ),\n",
    "            lx.data.Extraction(\n",
    "                extraction_class=\"emotion\",\n",
    "                extraction_text=\"But soft!\",\n",
    "                attributes={\"feeling\": \"gentle awe\"}\n",
    "            ),\n",
    "            lx.data.Extraction(\n",
    "                extraction_class=\"relationship\",\n",
    "                extraction_text=\"Juliet is the sun\",\n",
    "                attributes={\"type\": \"metaphor\"}\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    "]\n",
    "input_text = \"Lady Juliet gazed longingly at the stars, her heart aching for Romeo\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ccad50f",
   "metadata": {},
   "source": [
    "# Azure OpenAI Provider Example\n",
    "\n",
    "This example demonstrates using the Azure OpenAI provider for sentiment analysis of product reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "84409acb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[ScoredOutput(score=1.0, output='Sure! Please provide the text or content from which you would like me to extract characters, emotions, and relationships.')]]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "api_key = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "deployment = \"gpt-4o-mini\"\n",
    "\n",
    "config = lx.factory.ModelConfig(\n",
    "    model_id=f\"azure:{deployment}\",\n",
    "    provider=\"AzureOpenAILanguageModel\",\n",
    "    provider_kwargs={\n",
    "        \"api_key\": api_key,\n",
    "        \"azure_endpoint\": endpoint,\n",
    "    },\n",
    ")\n",
    "model = lx.factory.create_model(config)\n",
    "results = list(model.infer([prompt]))\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "463f89ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/hf/4r73f0yn4x9gfzn30y7r8w1h0000gn/T/ipykernel_55108/3449547232.py:27: UserWarning: The 'use_schema_constraints' parameter is ignored when 'model' or 'config' is provided. To use schema constraints, include them directly in your config's provider_kwargs (e.g., 'gemini_schema' for Gemini models).\n",
      "  result = lx.extract(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Correct Azure OpenAI Usage ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[94m\u001b[1mLangExtract\u001b[0m: model=\u001b[92mgpt-4o-mini\u001b[0m, current=\u001b[92m68\u001b[0m chars, processed=\u001b[92m68\u001b[0m chars:  [00:01]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m✓\u001b[0m Extraction processing complete\n",
      "\u001b[92m✓\u001b[0m Extracted \u001b[1m5\u001b[0m entities (\u001b[1m3\u001b[0m unique types)\n",
      "  \u001b[96m•\u001b[0m Time: \u001b[1m1.93s\u001b[0m\n",
      "  \u001b[96m•\u001b[0m Speed: \u001b[1m35\u001b[0m chars/sec\n",
      "  \u001b[96m•\u001b[0m Chunks: \u001b[1m1\u001b[0m\n",
      "✅ Extraction successful!\n",
      "Results: AnnotatedDocument(extractions=[Extraction(extraction_class='character', extraction_text='Lady Juliet', char_interval=CharInterval(start_pos=0, end_pos=11), alignment_status=<AlignmentStatus.MATCH_EXACT: 'match_exact'>, extraction_index=1, group_index=0, description=None, attributes={'emotional_state': 'longing'}), Extraction(extraction_class='emotion', extraction_text='gazed longingly', char_interval=CharInterval(start_pos=12, end_pos=27), alignment_status=<AlignmentStatus.MATCH_EXACT: 'match_exact'>, extraction_index=2, group_index=1, description=None, attributes={'feeling': 'desire'}), Extraction(extraction_class='emotion', extraction_text='her heart aching', char_interval=CharInterval(start_pos=42, end_pos=45), alignment_status=<AlignmentStatus.MATCH_LESSER: 'match_lesser'>, extraction_index=3, group_index=2, description=None, attributes={'feeling': 'pain'}), Extraction(extraction_class='character', extraction_text='Romeo', char_interval=CharInterval(start_pos=63, end_pos=68), alignment_status=<AlignmentStatus.MATCH_FUZZY: 'match_fuzzy'>, extraction_index=4, group_index=3, description=None, attributes={'emotional_state': 'desired'}), Extraction(extraction_class='relationship', extraction_text='heart aching for Romeo', char_interval=CharInterval(start_pos=46, end_pos=68), alignment_status=<AlignmentStatus.MATCH_EXACT: 'match_exact'>, extraction_index=5, group_index=4, description=None, attributes={'type': 'romantic longing'})], text='Lady Juliet gazed longingly at the stars, her heart aching for Romeo')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "api_key = os.environ.get('AZURE_OPENAI_API_KEY')\n",
    "endpoint = os.environ.get('AZURE_OPENAI_ENDPOINT')\n",
    "\n",
    "# 1. Create model configuration\n",
    "config = lx.factory.ModelConfig(\n",
    "    model_id=\"azure:gpt-4o-mini\",\n",
    "    provider=\"AzureOpenAILanguageModel\",\n",
    "    provider_kwargs={\n",
    "        \"api_key\": api_key,\n",
    "        \"azure_endpoint\": endpoint,\n",
    "    },\n",
    ")\n",
    "model = lx.factory.create_model(config)\n",
    "\n",
    "# 2. Use the model parameter (not model_id)\n",
    "result = lx.extract(\n",
    "    text_or_documents=\"Lady Juliet gazed longingly at the stars, her heart aching for Romeo\",\n",
    "    model=model,  # ← Use model parameter, not model_id\n",
    "    prompt_description=prompt,\n",
    "    examples=examples\n",
    ")\n",
    "print(\"✅ Extraction successful!\")\n",
    "print(f\"Results: {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8522df8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e98e6795",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "794f5076",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b988710a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82eaff2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f37053ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba8ba91f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0bdbb90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b6c7959",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d44cc72e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb5f2c18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e630d2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db95ce99",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13fdaeb3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LangExtract OpenAI (Python 3.13)",
   "language": "python",
   "name": "langextract-openai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
